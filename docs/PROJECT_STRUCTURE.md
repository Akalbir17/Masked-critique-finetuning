# Project Structure Documentation

This document explains the organization and purpose of each directory and file in the Masked Critique Fine-tuning project.

## ğŸ“ Directory Structure

```
masked-critique-finetuning/
â”œâ”€â”€ .github/                    # GitHub-specific files
â”‚   â””â”€â”€ workflows/             # GitHub Actions CI/CD
â”‚       â””â”€â”€ ci.yml            # Continuous Integration workflow
â”œâ”€â”€ btsft/                     # Core training infrastructure
â”‚   â”œâ”€â”€ __init__.py           # Package initialization
â”‚   â”œâ”€â”€ main.py               # CLI entry point
â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”œâ”€â”€ func/                 # Training utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ training.py       # Main training function
â”‚   â”‚   â”œâ”€â”€ format_reward.py  # Reward function implementation
â”‚   â”‚   â”œâ”€â”€ mapping.py        # Data mapping utilities
â”‚   â”‚   â””â”€â”€ parameters.py     # Parameter management
â”‚   â””â”€â”€ trainers/             # Custom trainer implementations
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ blurred_thoughts.py  # Masked Critique Trainer
â”œâ”€â”€ LIMO/                      # Benchmark evaluation framework
â”‚   â”œâ”€â”€ eval/                 # Evaluation scripts and metrics
â”‚   â”œâ”€â”€ train/                # Training configurations
â”‚   â”œâ”€â”€ data/                 # Benchmark datasets
â”‚   â””â”€â”€ README.md             # LIMO framework documentation
â”œâ”€â”€ config/                    # Training configurations
â”‚   â”œâ”€â”€ default.yaml          # Default training config
â”‚   â””â”€â”€ carc.yaml             # CARC cluster config
â”œâ”€â”€ scripts/                   # Utility and experiment scripts
â”‚   â”œâ”€â”€ benchmark_*.err       # Benchmark error logs
â”‚   â”œâ”€â”€ benchmark_*.out       # Benchmark output logs
â”‚   â””â”€â”€ run__inference.slurm # SLURM inference script
â”œâ”€â”€ docs/                      # Documentation and papers
â”‚   â”œâ”€â”€ figures/              # Research figures
â”‚   â”‚   â”œâ”€â”€ Fig 1.png        # Data Generation pipeline
â”‚   â”‚   â”œâ”€â”€ figure 2.png     # Training process
â”‚   â”‚   â”œâ”€â”€ Figure 3.png     # Sample Input/Output
â”‚   â”‚   â””â”€â”€ fig 4.png        # Inference process
â”‚   â”œâ”€â”€ paper.pdf             # Research paper (ACL template)
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md  # This file
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_trainer.py       # Trainer tests
â”œâ”€â”€ examples/                  # Usage examples
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ basic_training.py     # Basic training example
â”œâ”€â”€ data/                      # Data utilities and datasets
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # Data loading utilities
â”‚   â””â”€â”€ sanitized_data_v4.csv # Main training dataset
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ setup.py                  # Package installation
â”œâ”€â”€ run_btsft.slurm          # SLURM training script
â”œâ”€â”€ download_limo.py          # LIMO dataset downloader
â”œâ”€â”€ check_limo.py             # LIMO dataset checker
â”œâ”€â”€ README.md                 # Main project documentation
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ .gitignore               # Git ignore rules
```

## ğŸ”§ Core Components

### **btsft/** - Training Infrastructure
The main package containing the Masked Critique Fine-tuning implementation.

- **`main.py`**: Command-line interface entry point
- **`config.py`**: Configuration management and validation
- **`func/training.py`**: Main training loop and orchestration
- **`func/format_reward.py`**: Reward function for format adherence
- **`trainers/blurred_thoughts.py`**: Custom trainer with masked critique logic

### **LIMO/** - Evaluation Framework
Comprehensive benchmarking and evaluation tools for mathematical reasoning.

- **`eval/`**: Evaluation scripts for multiple benchmarks
- **`train/`**: Training configurations and utilities
- **`data/`**: Benchmark datasets (AIME, MATH-500, etc.)

### **config/** - Training Configurations
YAML configuration files for different training scenarios.

- **`default.yaml`**: Standard training configuration
- **`carc.yaml`**: CARC cluster-specific configuration

## ğŸ“Š Data Management

### **Main Dataset**
- **`data/sanitized_data_v4.csv`**: Primary training dataset with prompts and critiques
- **Size**: ~109MB (contains the core training data)
- **Format**: CSV with columns: `prompt`, `critique`, `answer_match`

### **Data Utilities**
- **`data/data_loader.py`**: Utilities for loading and validating datasets
- **Automatic filtering**: Removes invalid examples based on `answer_match` column
- **HuggingFace integration**: Converts to HuggingFace Dataset format

## ğŸš€ Training and Inference

### **Training Process**
1. **Data Loading**: Load sanitized dataset with automatic validation
2. **Token Masking**: Apply 15-20% masking to critique tokens
3. **Model Training**: Full fine-tuning with custom loss function
4. **Format Rewards**: Reward function ensures proper structure adherence

### **Inference Process**
1. **Question Input**: User provides mathematical question
2. **Model Processing**: Masked Critique Fine-tuned model processes input
3. **Structured Output**: Generates critique, reasoning, and boxed answer

## ğŸ§ª Testing and Quality Assurance

### **Unit Tests**
- **`tests/test_trainer.py`**: Tests for the Masked Critique Trainer
- **Mock-based testing**: Uses mocks for model and tokenizer dependencies
- **Loss computation tests**: Validates reward function integration

### **CI/CD Pipeline**
- **GitHub Actions**: Automated testing on push/PR
- **Multi-Python support**: Tests on Python 3.8, 3.9, 3.10
- **Code quality checks**: flake8, black, isort
- **Package building**: Automated package building on main branch

## ğŸ“š Documentation

### **Research Figures**
- **Figure 1**: Data generation pipeline visualization
- **Figure 2**: Training process diagram
- **Figure 3**: Sample input/output examples
- **Figure 4**: Inference process flow

### **Academic Documentation**
- **`docs/paper.pdf`**: Research paper (ACL template)
- **Comprehensive README**: Project overview, installation, usage
- **Code examples**: Working examples in `examples/` directory

## ğŸ” Configuration and Deployment

### **Training Configurations**
- **Model**: DeepScaleR-1.5B (full fine-tuning)
- **Precision**: bfloat16 with gradient checkpointing
- **Optimizer**: Adam8bit with cosine learning rate
- **Sequence Length**: 16,394 tokens maximum

### **Hardware Requirements**
- **GPU**: A40 or equivalent (24GB+ VRAM recommended)
- **Memory**: 40% reduction through gradient checkpointing
- **Distributed**: DeepSpeed ZeRO-3 support for multi-GPU

## ğŸš€ Quick Start Commands

```bash
# Install the package
pip install -e .

# Run basic training example
python examples/basic_training.py

# Load and validate dataset
python data/data_loader.py

# Run tests
pytest tests/

# Train with custom config
mcf --config config/default.yaml
```

## ğŸ“ Contributing

1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/amazing-feature`
3. **Make changes** with proper testing
4. **Run quality checks**: `black .`, `isort .`, `flake8 .`
5. **Submit pull request**

## ğŸ”— External Dependencies

- **Hugging Face**: Transformers, Datasets, Accelerate
- **PyTorch**: Core deep learning framework
- **Unsloth**: Training optimization
- **DeepSpeed**: Distributed training
- **LIMO**: Benchmark evaluation framework

This structure provides a clean, organized, and professional research codebase that's ready for GitHub and academic collaboration.
